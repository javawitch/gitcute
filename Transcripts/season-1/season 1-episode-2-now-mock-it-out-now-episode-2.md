Speaker 1 (00:00):
Welcome back to the GQ podcast. Today we are going to be talking about software testing. Yay. Stay tuned.

Speaker 1 (00:18):
Hello. Welcome back for episode two I am so excited that I get to record another episode because software testing is something that I am very passionate about and I'm a huge advocate for to this episode is going to be full of rants and judging of people that don't test and I will not apologize for that because if you are a software engineer in 2019 and you are not at the very least unit testing your code, who are you like how'd you get here? How has your application or website silver, I need to know I if you are someone that does not test in 2019 and you haven't had any major hiccups or mishaps over the length of your career by not doing any of that, I want you to email me. I want you to do that right now because I don't believe you.

Speaker 1 (01:14):
I don't believe it. Okay. In all seriousness though. I love software testing and I feel as though if a, if you are somebody that is new to testing, you may only know unit testing or maybe you don't know any testing at all. I will say that when I came out of my bootcamp I at the very, very, very bare minimum new unit testing, I knew J unit and I can write J unit tests like a motherfucker, but when I got into my first job at a fortune 100 company, I was looking at these integration tests like who, where, what are these? So hopefully that this podcast will give you some base knowledge of what it's like to test in a, I don't want to say corporate because that just seems so off. How about an UN, a working dev environment, how's that? We'll go with that.

Speaker 1 (02:12):
Why do software engineer's tests to begin with? We test because we want to fail fast and we want to fail early. What this means essentially is we want to have our code unit tested and to sizable chunks so that if something breaks we can easily pinpoint where that break is. And get working on a solution to fix it. It takes out the guesswork of sitting through code and trying to figure it out what it is. I suppose in some sense if you have, say you're just writing a mobile app and you're the only developer on that app and you've written every bit of code on it and you don't want to do tests for that. Okay. I still don't agree with it, but that's a scenario that I can think of that it would be acceptable to not unit tests. Although if anything that you are at, if you're providing a product to a user base, it's irresponsible to not unit tests because you know what? If you want to lose some money, that's fine. The companies that I've worked for, minus one, they care if a site goes down because they're losing money at that point in their infuriating customers. So

Speaker 1 (03:35):
Maybe end rant. I feel like this entire episode is going to be nothing but a rant about unit testing. And anyway, as I've said, I have worked for a company where we did not test anything. I worked at this company for less than a year. I worked before I left. I actually had to implement a very basic selenium component testing suite for them because they didn't test anything. I remember going, y'all don't, y'all don't test your code. Then I remember my CTO going that it would be a company culture change in order to implement testing, which is,

Speaker 2 (04:15):
Oh brother, this guy stinks.

Speaker 1 (04:19):
I mean girl I guess, but at the same time, how are you managing all of these websites and products without even having the basic unit testing? I want to say that there is a testing library or framework for almost anything that you can imagine. Any language, anything, anything, think anything to say that it doesn't need to be tested or it cannot be tested means that you didn't do a basic Google or is that just not the mindset that you have? I will say this and then I will stop ranting that you cannot call yourself a good developer or software engineer if you don't, at the very least unit test your code period.

Speaker 2 (05:07):
Piri piri piri

Speaker 1 (05:11):
The point of this episode is that you do want to be a good software developer or software engineer, so please unit test your code at the bare minimum. I understand that a lot of people may not have the ideal company or work environment that puts focus on testing. I've seen it and a lot of bigger companies and a lot of smaller companies, oddly enough like startups that they put value on software development unit testing, bigger companies more so because they've had errors happen in the past where it's cost them a lot of money, so now they're pushing for testing. If you are brand new to software development and you have no idea, this is the simplest explanation that I can think of. Unit testing is where you are taking your code base and you are breaking it down into manageable chunks, hence why it's called unit testing and writing tests to make sure that the functionality outputs what the application needs in order for it to run successfully.

Speaker 1 (06:17):
Test driven development is not a new concept, but I do feel that it is a concept that if you have say, Ooh, I'm going to hit get heat for this, but if you are a person that has been working for X amount of time in the industry, in your custom to one way of delivering code and you have all of these new processes and methodologies that your company wants you to implement, test driven development is usually the one methodology that put is put in the bin. Test driven development is when you are writing your test first and refactoring your code to make your Tesco red or green, which means it passes or fails. So you may be asking yourself, Jocelyn, unit testing seems so simple and it is at some point, but where can it go wrong? I'll tell you, I'll give you one. I'll give you two points of where it can go wrong.

Speaker 1 (07:20):
A making your unit test way too specific. When you write unit tests, again, you are writing tests to make sure that that unit of code is giving you the output that you need. And a more specific way of saying that is making sure that you're testing for the behavior, not specific functionalities within that unit of code. Another way for unit testing to go wrong is mocking. Mocking is providing fake data that is a simulation of an actual behavior of an object. The general rule of thumb is that you should not mock everything mocking everything is as bad as testing every little bit of functionality within your code base. Remember we are testing behavior. If it has an external dependence such as a database connection, then it should be mocked and or stubbed. It depends on which one you would rather do stubbing. You can generate a an object and give a fake data and you can test against that. Mocking an object is just mocking the objects behavior. Now you're probably asking, well, Joslin why would we want to mock that database connection instead of just them using the database connection?

Speaker 3 (08:33):
Yeah.

Speaker 1 (08:34):
There are a couple of reasons why you would not want to actually use a database connection within your tests. The most basic one is what if your database connection fails?

Speaker 1 (08:46):
How are you going to run your tests? What are your tests running against? Another reason is what if you write your unit tests wrong and you somehow populate fake data, your database and now you're using your prod database that has fake data and now you're going to have to go into the database to delete data, which is a horror within itself because why would you ever want to go in and modify it production database on your own. That is something that you should probably should not be doing ever and I feel sorry for people that are forced to do that. I feel that's so hard because that would be an anxiety attack for me every time I would have to log into that database. Another reason to not use like a live database connection would be what if somehow the behavior of that database changes.

Speaker 1 (09:29):
What if you are refactoring the tables or you're adding or removing columns or data? Why would you want to be testing against that? Again, you're testing the behavior, not the actual data that is in the database, so mocking it should be fine. I'm hoping that the section on unit tests empowers you to start unit testing your code. At the very least, I do understand that there are some companies and some teams and some tech leads that find testing to be a waste of time. While they are wrong, at least for your own personal development, start implementing it in unit tests for the code that you write in the code that you touch. It will make you a better software engineer and who knows, perhaps your tech lead or your team or your company might actually start paying attention when they see the decrease in prod incidents.

Speaker 2 (10:17):
Just saying

Speaker 1 (10:21):
Now we're onto one of my favorite parts of testing. It's very weird for me to say that I have a favorite part of testing, but I feel like at a very high level, integration and regression testing is pretty spectacular, so if you have no idea what integration or regression testing is, let's just start with a definition of integration testing. Integration testing is at a very high level, making sure that the components or units of your code behave in a flow that is supposed to example say that you are adding on your front end. Say that you're adding new back button. You've already tested the unit to make sure that the back functionality does what it needs to do. Now you are going to be writing a component test to make sure that that component does not break or hinder any already existing features that are on that front end.

Speaker 1 (11:14):
Regression testing is simply most of the time, that same set of integration tasks that you've already written in Vardy run more than likely, but before you go to prod, they are run again to double check and make sure that nothing's broken before we push. I think it's important that I understand very, very high level about it get flow because it comes into play when you're talking about integration, regression testing, and also when you're talking about continuous deployment and continuous integration. So a good flow is where you have a set of environments that you, your code progresses through before it gets to prod. In an ideal world, you would have a dev environment, you would have a QA environment, you would have a staging environment and then you would have prod, which is your main environment, not all teams. And not all companies are set up this way.

Speaker 1 (12:05):
So it's important for me to let you know what these things are. So dev and dev environment is exactly what it says. That's where all of your currently being developed work would be pushed to. At my current company, we don't have that. We do most of our developing changes on local and we use QA as or devil development to make sure that it's supposed to work. The way that it's going to QA is quality assurance. This is when your code is done and you've tested it and you fit in, you're testing your local or dev environment and then you've pushed them up to QA to make sure that everything's working and nothing's broken. The issue with QA sometimes is that obviously there are multiple other teams that are going to be working on QA. Not every team can be afforded to have their own personal QA environment, especially if you're just one team that's working on a very small portion of the site.

Speaker 1 (12:53):
I would liken it to say something like Amazon. Amazon is a huge website, but one team obviously does not work on every single component that's on Amazon. It's impossible. Staging is an ideal environment. Actually, dev and staging are both ideal environments. If we lived in a perfect world, would where I would be able to set up a good flow, I would more than likely want to staging environments. So staging environments are typically supposed to be a direct replica of whatever was in prod because that way the code that it's ready to be deployed whenever you're released, it's going to be it sits and staging. The reason I'm explaining this is is that normally your integration tasks and your regression tests are run between each environment that you're pushing up to regression test more so when you are about to post a prod. In my past experience with integrations or taxed are typically run as soon as you raise a PR or a pull request to your get repository.

Speaker 1 (13:47):
So while before you can even merge that PR into your code base, the integration tests run to make sure that nothing that you're adding is going to break any existing functionality and that's really important. Then when you're pushing from say, let's just simplify and say QA to prod, cause most of the time that's what's going to happen. In an ideal world, again, like I said, we'd have a staging environment but sometimes that's just not feasible. This same tests we is run again but this time it's called regression testing and like I said, regression testing is the test set of integration tests that you've already run. So it's the same exact same test code base, but they're running it again to double check to make sure that your changes, that there isn't something that's missing QA and that it actually won't mess up anything in prod.

Speaker 1 (14:34):
And the issue with this is because QA most of the time, 100% of the time differs from prod because like I said before, they're done multiple teams pushing things to pride, testing them, making sure everything is good before we actually push it out to the customer. A software engineer is going to have a very bad day if a feature they pushed a prod breaks but you know what's even worse if your break actually takes down other functionality down with it. So that's why integration Eric regression testing is so important and when you're trying to figure out how to fix that break, that's where your unit testing comes in as well. So far mentioned test driven development and also behavior driven development. What the hell are either one of these things? Which one do I use over the other? To be honest, you use some together, you can't have test driven development without behavior driven development and vice versa.

Speaker 1 (15:21):
Both of these practices are the best practice for writing your test suite. Cody utopia.com had the best and the most simple explanation for this unit test. So your what test driven development is your when and behavior driven development is your, how all three of these things are essential and writing the best test suite for your code. I see behavior driven development as a cohesive language between the software engineers testing. If you're lucky enough to have your own set of key ways and business, it defines the behavior of the feature and we're going to talk at a feature level now or task as in layman terms as acceptance criteria. So it doesn't matter if you're a software engineer or a BA or product owner or product manager or even a scrum master. Everybody is on the same page as knowing to what this feature supposed to do, what it's supposed to look like and how it's supposed to be formed for the user.

Speaker 1 (16:13):
My current team actually uses gherkins and tacks in our stories so that way you already have the base of your integration testing before you even start writing. The acceptance criteria is to find during story creation, depending on whoever writes it. It could be me, it could be my tech lead, it could be our product owner, but that is part of the story and then it's actually reviewed during our grooming sessions to make sure that the acceptance criteria and the behavior that we're expecting aligns across all aspects of the team. Gherkin is a syntax of cucumber, which is an open source testing framework to make it as simple as possible. The best part about Gherkin and cucumber is that the syntax allows everybody, as I mentioned before, to be able to read this and be able to understand what behavior is expected from this feature. The most simple test that I can think of would be a given a when and then so first you define a scenario for your test and then with a given, so given this scenario, when this action is taken, then this result will happen.

Speaker 1 (17:21):
It reads just like a sentence. It makes it super easy for everybody to understand what this is supposed to be. Usually the syntax for us is for whenever who writes the story, so it could be an individual software engineer on the team. Perhaps my tech lead writes it or perhaps my product owner or my scrum master writes that there's a lot of moving parts in this so therefore when we get to grooming the person brings it the story for the grooming session and then we can collaborate as a team to make sure that this is supposed to be the exact that is supposed to happen for the user and that's the end of the episode of our software test saying so excited to keep this under 20 minutes. Ideally I want it two episodes, but I thought that would've been too much information to push at y'all at this time.

Speaker 1 (18:04):
If you like this episode or you liked my previous episode, please feel free to leave me a five star rating on Apple podcast or wherever you are listening to this. You know how algorithms are. The more five star ratings I get, the better chances are I will be able to actually have this podcast reach other people that are interested in software engineering as much as I am or anybody else that is new to it. If you have any questions, comments, or concerns, feel free to email me@thegetcutiepiecasteatgmail.com Oh, and I also have social media. Now. I have Instagram and a Twitter account. They're both at get cute podcasts, so feel free to follow both of those accounts because you'll know about the episodes before anybody else will. All right, that's it. I shall see y'all next week.

Speaker 4 (18:59):
[Inaudible].

